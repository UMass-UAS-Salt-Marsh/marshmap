{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmknlbLyPF2J"
   },
   "source": [
    "\n",
    "### This version does not use dask to load imagery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M2Gz90bpcNj3",
    "outputId": "9c819ed1-6036-40ba-c437-64e4f491c962"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hlWn28OfcTGq"
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal, ogr, gdal_array # I/O image data\n",
    "import numpy as np # math and array handling\n",
    "import matplotlib.pyplot as plt # plot figures\n",
    "from sklearn.ensemble import RandomForestClassifier # classifier\n",
    "import pandas as pd # handling large data as table sheets\n",
    "from sklearn.metrics import classification_report, accuracy_score,confusion_matrix  # calculating measures for accuracy assessment\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "import datetime\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uPX1k_NX5cc-"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.environ['GDAL_NUM_THREADS'])\n",
    "os.environ['PROJ_LIB'] = \"/work/pi_gstuart_umass_edu/kate/conda/share/proj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bneZO374zh9x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available attributes in the shape file are: ['Transect', 'PointNum', 'SubClass', 'Northing', 'Easting', 'Altitude', 'Notes', 'Class', 'Raw Subcla', 'Pre Angle', 'Post Angle', 'mu', 'Class mu', 'Pre/Post', 'Hydro', 'ReClaSch A']\n"
     ]
    }
   ],
   "source": [
    "# Tell GDAL to throw Python exceptions, and register all drivers\n",
    "gdal.UseExceptions()\n",
    "gdal.AllRegister()\n",
    "\n",
    "# define a number of trees that should be used (default = 500)\n",
    "est = 500\n",
    "\n",
    "# how many cores should be used?\n",
    "# -1 -> all available cores\n",
    "n_cores = 60\n",
    "\n",
    "# the remote sensing image you want to classify\n",
    "img_RS = r'/work/pi_gstuart_umass_edu/kate/allstacked_v1.tif'\n",
    "\n",
    "\n",
    "# training and validation as shape files\n",
    "training = r'/work/pi_gstuart_umass_edu/kate/OTH_Training_Data/OTH_Polygons_v3_relassed.shp'\n",
    "validation = r'/work/pi_gstuart_umass_edu/kate/OTH_Training_Data/OTH_Polygons_v3_relassed.shp'\n",
    "\n",
    "# what is the attributes name of your classes in the shape file (field name of the classes)?\n",
    "attribute = 'ReClaSch A'\n",
    "\n",
    "\n",
    "# directory, where the classification image should be saved:\n",
    "classification_image = r'/work/pi_gstuart_umass_edu/kate/Classification_products/OTH_all_reclass_classification_v1.gtif'\n",
    "\n",
    "# directory, where the all meta results should be saved:\n",
    "results_txt = r'/work/pi_gstuart_umass_edu/kate/Classification_products/OTH_all_reclass_classification_v1.txt'\n",
    "\n",
    "# laod training data and show all shape attributes\n",
    "\n",
    "#model_dataset = gdal.Open(model_raster_fname)\n",
    "shape_dataset = ogr.Open(training)\n",
    "shape_layer = shape_dataset.GetLayer()\n",
    "\n",
    "# extract the names of all attributes (fieldnames) in the shape file\n",
    "attributes = []\n",
    "ldefn = shape_layer.GetLayerDefn()\n",
    "for n in range(ldefn.GetFieldCount()):\n",
    "    fdefn = ldefn.GetFieldDefn(n)\n",
    "    attributes.append(fdefn.name)\n",
    "    \n",
    "# print the attributes\n",
    "print('Available attributes in the shape file are: {}'.format(attributes))\n",
    "\n",
    "# prepare results text file:\n",
    "\n",
    "print('Random Forest Classification', file=open(results_txt, \"a\"))\n",
    "print('Processing: {}'.format(datetime.datetime.now()), file=open(results_txt, \"a\"))\n",
    "print('-------------------------------------------------', file=open(results_txt, \"a\"))\n",
    "print('PATHS:', file=open(results_txt, \"a\"))\n",
    "print('Image: {}'.format(img_RS), file=open(results_txt, \"a\"))\n",
    "print('Training shape: {}'.format(training) , file=open(results_txt, \"a\"))\n",
    "print('Vaildation shape: {}'.format(validation) , file=open(results_txt, \"a\"))\n",
    "print('      choosen attribute: {}'.format(attribute) , file=open(results_txt, \"a\"))\n",
    "print('Classification image: {}'.format(classification_image) , file=open(results_txt, \"a\"))\n",
    "print('Report text file: {}'.format(results_txt) , file=open(results_txt, \"a\"))\n",
    "print('-------------------------------------------------', file=open(results_txt, \"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bneZO374zh9x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12434, 13246, 142) <class 'numpy.float32'> 4\n",
      "4\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# load image data\n",
    "######THIS IS STEP THAT TAKES A LONG TIME#######\n",
    "\n",
    "img_ds = gdal.Open(img_RS, gdal.GA_ReadOnly)\n",
    "\n",
    "img = np.zeros((img_ds.RasterYSize, img_ds.RasterXSize, img_ds.RasterCount),\n",
    "               gdal_array.GDALTypeCodeToNumericTypeCode(img_ds.GetRasterBand(1).DataType))\n",
    "print(img.shape, gdal_array.GDALTypeCodeToNumericTypeCode(img_ds.GetRasterBand(1).DataType), img.itemsize)\n",
    "print(img_ds.GetRasterBand(1).ReadAsArray().itemsize)\n",
    "for b in range(img.shape[2]):\n",
    "    print(b)\n",
    "    img[:, :, b] = img_ds.GetRasterBand(b + 1).ReadAsArray()\n",
    "    \n",
    "row = img_ds.RasterYSize\n",
    "col = img_ds.RasterXSize\n",
    "band_number = img_ds.RasterCount\n",
    "\n",
    "print('Image extent: {} x {} (row x col)'.format(row, col))\n",
    "print('Number of Bands: {}'.format(band_number))\n",
    "\n",
    "\n",
    "print('Image extent: {} x {} (row x col)'.format(row, col), file=open(results_txt, \"a\"))\n",
    "print('Number of Bands: {}'.format(band_number), file=open(results_txt, \"a\"))\n",
    "print('---------------------------------------', file=open(results_txt, \"a\"))\n",
    "print('TRAINING', file=open(results_txt, \"a\"))\n",
    "print('Number of Trees: {}'.format(est), file=open(results_txt, \"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bneZO374zh9x"
   },
   "outputs": [],
   "source": [
    "# laod training data from shape file\n",
    "# img_ds = gdal.Open(img_RS, gdal.GA_ReadOnly)\n",
    "\n",
    "#model_dataset = gdal.Open(model_raster_fname)\n",
    "shape_dataset = ogr.Open(training)\n",
    "shape_layer = shape_dataset.GetLayer()\n",
    "\n",
    "mem_drv = gdal.GetDriverByName('MEM')\n",
    "mem_raster = mem_drv.Create('',img_ds.RasterXSize,img_ds.RasterYSize,1,gdal.GDT_UInt16)\n",
    "#mem_raster.SetProjection(img_ds.GetProjection())\n",
    "mem_raster.SetGeoTransform(img_ds.GetGeoTransform())\n",
    "mem_band = mem_raster.GetRasterBand(1)\n",
    "mem_band.Fill(0)\n",
    "mem_band.SetNoDataValue(0)\n",
    "\n",
    "att_ = 'ATTRIBUTE='+attribute\n",
    "# http://gdal.org/gdal__alg_8h.html#adfe5e5d287d6c184aab03acbfa567cb1\n",
    "# http://gis.stackexchange.com/questions/31568/gdal-rasterizelayer-doesnt-burn-all-polygons-to-raster\n",
    "err = gdal.RasterizeLayer(mem_raster, [1], shape_layer, None, None, [1],  [att_,\"ALL_TOUCHED=TRUE\"])\n",
    "assert err == gdal.CE_None\n",
    "\n",
    "roi = mem_raster.ReadAsArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bneZO374zh9x"
   },
   "outputs": [],
   "source": [
    "# # Display images\n",
    "# plt.subplot(121)\n",
    "# plt.imshow(img[:, :, 0], cmap=plt.cm.Greys_r)\n",
    "# plt.title('RS image - first band')\n",
    "\n",
    "# plt.subplot(122)\n",
    "# plt.imshow(roi, cmap=plt.cm.Spectral)\n",
    "# plt.title('Training Image')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# Number of training pixels:\n",
    "n_samples = (roi > 0).sum()\n",
    "print('{n} training samples'.format(n=n_samples))\n",
    "print('{n} training samples'.format(n=n_samples), file=open(results_txt, \"a\"))\n",
    "\n",
    "# What are our classification labels?\n",
    "labels = np.unique(roi[roi > 0])\n",
    "print('training data include {n} classes: {classes}'.format(n=labels.size, classes=labels))\n",
    "print('training data include {n} classes: {classes}'.format(n=labels.size, classes=labels), file=open(results_txt, \"a\"))\n",
    "\n",
    "# Subset the image dataset with the training image = X\n",
    "# Mask the classes on the training dataset = y\n",
    "# These will have n_samples rows\n",
    "X = img[roi > 0, :]\n",
    "y = roi[roi > 0]\n",
    "\n",
    "print('Our X matrix is sized: {sz}'.format(sz=X.shape))\n",
    "print('Our y array is sized: {sz}'.format(sz=y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bneZO374zh9x"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=est, oob_score=True, verbose=1, n_jobs=n_cores)\n",
    "\n",
    "# verbose = 2 -> prints out every tree progression\n",
    "# rf = RandomForestClassifier(n_estimators=est, oob_score=True, verbose=2, n_jobs=n_cores)\n",
    "\n",
    "\n",
    "\n",
    "X = np.nan_to_num(X)\n",
    "rf2 = rf.fit(X, y)\n",
    "\n",
    "\n",
    "# Save the trained model to a file\n",
    "pickle_file = '/work/pi_gstuart_umass_edu/kate/Classification_products/RF_alldata_v1.pkl'\n",
    "with open(pickle_file, 'wb') as file:\n",
    "    pickle.dump(rf2, file)\n",
    "\n",
    "print ('model pickled')\n",
    "\n",
    "# With our Random Forest model fit, we can check out the \"Out-of-Bag\" (OOB) prediction score:\n",
    "\n",
    "print('--------------------------------', file=open(results_txt, \"a\"))\n",
    "print('TRAINING and RF Model Diagnostics:', file=open(results_txt, \"a\"))\n",
    "print('OOB prediction of accuracy is: {oob}%'.format(oob=rf.oob_score_ * 100))\n",
    "print('OOB prediction of accuracy is: {oob}%'.format(oob=rf.oob_score_ * 100), file=open(results_txt, \"a\"))\n",
    "\n",
    "\n",
    "# we can show the band importance:\n",
    "bands = range(1,img_ds.RasterCount+1)\n",
    "\n",
    "for b, imp in zip(bands, rf2.feature_importances_):\n",
    "    print('Band {b} importance: {imp}'.format(b=b, imp=imp))\n",
    "    print('Band {b} importance: {imp}'.format(b=b, imp=imp), file=open(results_txt, \"a\"))\n",
    "\n",
    "    \n",
    "# Let's look at a crosstabulation to see the class confusion. \n",
    "# To do so, we will import the Pandas library for some help:\n",
    "# Setup a dataframe -- just like R\n",
    "# Exception Handling because of possible Memory Error\n",
    "\n",
    "try:\n",
    "    df = pd.DataFrame()\n",
    "    df['truth'] = y\n",
    "    df['predict'] = rf.predict(X)\n",
    "\n",
    "except MemoryError:\n",
    "    print('Crosstab not available ')\n",
    "\n",
    "else:\n",
    "    # Cross-tabulate predictions\n",
    "    print(pd.crosstab(df['truth'], df['predict'], margins=True))\n",
    "    print(pd.crosstab(df['truth'], df['predict'], margins=True), file=open(results_txt, \"a\"))\n",
    "    \n",
    "# Predicting the rest of the image\n",
    "\n",
    "# generate mask image from red band\n",
    "mask = np.copy(img[:,:,0])\n",
    "mask[mask > 0.0] = 1.0 # all actual pixels have a value of 1.0\n",
    "\n",
    "# Take our full image and reshape into long 2d array (nrow * ncol, nband) for classification\n",
    "old_shape = img.shape\n",
    "new_shape = (img.shape[0] * img.shape[1], img.shape[2])\n",
    "# img = img[:, :, :int(img.shape[2])].reshape(new_shape)\n",
    "img = img.reshape(new_shape)\n",
    "\n",
    "print('Reshaped from {o} to {n}'.format(o=old_shape, n=img.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vrB7XKyDr3LH"
   },
   "outputs": [],
   "source": [
    "# img = np.nan_to_num(img)\n",
    "img[np.isnan(img)] = 0.0\n",
    "# class_prediction = rf.predict(img)\n",
    "\n",
    "print (\"DONE!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hp8gwSplB0LJ"
   },
   "source": [
    "# **Apply Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z4Sry-DPcVpQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "slices = int(round(len(img)/20))\n",
    "\n",
    "test = True\n",
    "\n",
    "while test == True:\n",
    "    try:\n",
    "        class_preds = list()\n",
    "\n",
    "        temp = rf.predict(img[0:slices+1,:])\n",
    "        class_preds.append(temp)\n",
    "\n",
    "        for i in range(slices,len(img),slices):\n",
    "            print('{} %, derzeit: {}'.format((i*100)/(len(img)), i))\n",
    "            temp = rf.predict(img[i+1:i+(slices+1),:])                \n",
    "            class_preds.append(temp)\n",
    "\n",
    "    except MemoryError as error:\n",
    "        slices = slices/4\n",
    "        print('Not enought RAM, new slices = {}'.format(slices))\n",
    "\n",
    "    else:\n",
    "        test = False\n",
    "else:\n",
    "    print('Class prediction was successful without slicing!')\n",
    "#concatenate all slices and re-shape it to the original extend\n",
    "try:\n",
    "    class_prediction = np.concatenate(class_preds,axis = 0)\n",
    "except NameError:\n",
    "    print('No slicing was necessary!')\n",
    "    \n",
    "class_prediction = class_prediction.reshape(old_shape[:2])\n",
    "print('Reshaped back to {}'.format(class_prediction.shape))\n",
    "\n",
    "\n",
    "# # generate mask image from red band\n",
    "# mask = np.copy(img[:,:,0])\n",
    "# mask[mask > 0.0] = 1.0 # all actual pixels have a value of 1.0\n",
    "\n",
    "# plot mask\n",
    "\n",
    "# plt.imshow(mask)\n",
    "\n",
    "# mask classification an plot\n",
    "\n",
    "class_prediction.astype(np.float16)\n",
    "class_prediction_ = class_prediction*mask\n",
    "\n",
    "cols = class_prediction.shape[1]\n",
    "rows = class_prediction.shape[0]\n",
    "\n",
    "class_prediction_.astype(np.float16)\n",
    "\n",
    "driver = gdal.GetDriverByName(\"gtiff\")\n",
    "outdata = driver.Create(classification_image, cols, rows, 1, gdal.GDT_UInt16)\n",
    "outdata.SetGeoTransform(img_ds.GetGeoTransform())##sets same geotransform as input\n",
    "outdata.SetProjection(img_ds.GetProjection())##sets same projection as input\n",
    "outdata.GetRasterBand(1).WriteArray(class_prediction_)\n",
    "outdata.FlushCache() ##saves to disk!!\n",
    "del outdata\n",
    "print('Image saved to: {}'.format(classification_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Kate",
   "language": "python",
   "name": "kate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
