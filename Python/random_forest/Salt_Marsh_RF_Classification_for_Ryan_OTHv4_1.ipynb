{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmknlbLyPF2J"
   },
   "source": [
    "\n",
    "### This version does not use dask to load imagery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M2Gz90bpcNj3",
    "outputId": "9c819ed1-6036-40ba-c437-64e4f491c962"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "#comment test, 15 Sep 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hlWn28OfcTGq"
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal, ogr, gdal_array # I/O image data\n",
    "import numpy as np # math and array handling\n",
    "import matplotlib.pyplot as plt # plot figures\n",
    "from sklearn.ensemble import RandomForestClassifier # classifier\n",
    "import pandas as pd # handling large data as table sheets\n",
    "from sklearn.metrics import classification_report, accuracy_score,confusion_matrix  # calculating measures for accuracy assessment\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "import datetime\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uPX1k_NX5cc-"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# print(os.environ['GDAL_NUM_THREADS'])\n",
    "os.environ['PROJ_LIB'] = \"/work/pi_gstuart_umass_edu/kate/conda/share/proj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bneZO374zh9x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available attributes in the shape file are: ['fid', 'id', 'left', 'top', 'right', 'bottom', 'Raw Subcla', 'Transect', 'PointNum', 'SubClass', 'Northing', 'Easting', 'Altitude', 'Notes', 'Class', 'Pre Angle', 'Post Angle', 'mu', 'Class mu', 'Pre/Post', 'Hydro', 'ReclassV2', 'layer', 'path', 'area', 'ReclassV3', 'ReClass v4']\n"
     ]
    }
   ],
   "source": [
    "# Tell GDAL to throw Python exceptions, and register all drivers\n",
    "gdal.UseExceptions()\n",
    "gdal.AllRegister()\n",
    "\n",
    "# define a number of trees that should be used (default = 500)\n",
    "est = 500\n",
    "\n",
    "# how many cores should be used?\n",
    "# -1 -> all available cores\n",
    "n_cores = 60\n",
    "\n",
    "# the remote sensing image you want to classify\n",
    "# img_RS = r'/work/pi_cschweik_umass_edu/Ryan/Modeling_stack/Mid_High_Stacked_Clipped.tif'\n",
    "img_RS = r'/work/pi_cschweik_umass_edu/Ryan/Modeling_stack/allstacked_v1.tif'\n",
    "\n",
    "# training and validation as shape files\n",
    "# training = r'/work/pi_gstuart_umass_edu/kate/OTH_Training_Data/OTH_Polygons_v3_relassed.shp'\n",
    "# validation = r'/work/pi_gstuart_umass_edu/kate/OTH_Training_Data/OTH_Polygons_v3_relassed.shp'\n",
    "\n",
    "training = r'/work/pi_cschweik_umass_edu/Ryan/OTH_Ground_Truth_Data/OTH_Poygons_RCW_20Jul2023_4326.shp'\n",
    "validation = r'/work/pi_cschweik_umass_edu/Ryan/OTH_Ground_Truth_Data/OTH_Poygons_RCW_20Jul2023_4326.shp'\n",
    "\n",
    "# what is the attributes name of your classes in the shape file (field name of the classes)?\n",
    "# attribute = 'ReClassV3'\n",
    "attribute = 'ReClass v4'\n",
    "\n",
    "# directory, where the classification image should be saved:\n",
    "# classification_image = r'/work/pi_gstuart_umass_edu/kate/Classification_products/OTH_all_reclass_classification_v1.gtif'\n",
    "classification_image = r'/work/pi_cschweik_umass_edu/Ryan/Classification_products/OTH_all_reclass_classification_v4_s2.gtif'\n",
    "\n",
    "# directory, where the all meta results should be saved:\n",
    "# results_txt = r'/work/pi_gstuart_umass_edu/kate/Classification_products/OTH_all_reclass_classification_v1.txt'\n",
    "results_txt = r'/work/pi_cschweik_umass_edu/Ryan/Classification_products/OTH_all_reclass_classification_v4_s2.txt'\n",
    "\n",
    "# laod training data and show all shape attributes\n",
    "\n",
    "#model_dataset = gdal.Open(model_raster_fname)\n",
    "shape_dataset = ogr.Open(training)\n",
    "shape_layer = shape_dataset.GetLayer()\n",
    "\n",
    "# extract the names of all attributes (fieldnames) in the shape file\n",
    "attributes = []\n",
    "ldefn = shape_layer.GetLayerDefn()\n",
    "for n in range(ldefn.GetFieldCount()):\n",
    "    fdefn = ldefn.GetFieldDefn(n)\n",
    "    attributes.append(fdefn.name)\n",
    "    \n",
    "# print the attributes\n",
    "print('Available attributes in the shape file are: {}'.format(attributes))\n",
    "\n",
    "# prepare results text file:\n",
    "\n",
    "print('Random Forest Classification', file=open(results_txt, \"a\"))\n",
    "print('Processing: {}'.format(datetime.datetime.now()), file=open(results_txt, \"a\"))\n",
    "print('-------------------------------------------------', file=open(results_txt, \"a\"))\n",
    "print('PATHS:', file=open(results_txt, \"a\"))\n",
    "print('Image: {}'.format(img_RS), file=open(results_txt, \"a\"))\n",
    "print('Training shape: {}'.format(training) , file=open(results_txt, \"a\"))\n",
    "print('Vaildation shape: {}'.format(validation) , file=open(results_txt, \"a\"))\n",
    "print('      choosen attribute: {}'.format(attribute) , file=open(results_txt, \"a\"))\n",
    "print('Classification image: {}'.format(classification_image) , file=open(results_txt, \"a\"))\n",
    "print('Report text file: {}'.format(results_txt) , file=open(results_txt, \"a\"))\n",
    "print('-------------------------------------------------', file=open(results_txt, \"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bneZO374zh9x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12434, 13246, 142) <class 'numpy.uint16'> 2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "Image extent: 12434 x 13246 (row x col)\n",
      "Number of Bands: 142\n"
     ]
    }
   ],
   "source": [
    "# load image data\n",
    "######THIS IS STEP THAT TAKES A LONG TIME#######\n",
    "\n",
    "img_ds = gdal.Open(img_RS, gdal.GA_ReadOnly)\n",
    "\n",
    "img = np.zeros((img_ds.RasterYSize, img_ds.RasterXSize, img_ds.RasterCount),\n",
    "               gdal_array.GDALTypeCodeToNumericTypeCode(img_ds.GetRasterBand(1).DataType))\n",
    "print(img.shape, gdal_array.GDALTypeCodeToNumericTypeCode(img_ds.GetRasterBand(1).DataType), img.itemsize)\n",
    "print(img_ds.GetRasterBand(1).ReadAsArray().itemsize)\n",
    "for b in range(img.shape[2]):\n",
    "    print(b)\n",
    "    img[:, :, b] = img_ds.GetRasterBand(b + 1).ReadAsArray()\n",
    "    \n",
    "row = img_ds.RasterYSize\n",
    "col = img_ds.RasterXSize\n",
    "band_number = img_ds.RasterCount\n",
    "\n",
    "print('Image extent: {} x {} (row x col)'.format(row, col))\n",
    "print('Number of Bands: {}'.format(band_number))\n",
    "\n",
    "\n",
    "print('Image extent: {} x {} (row x col)'.format(row, col), file=open(results_txt, \"a\"))\n",
    "print('Number of Bands: {}'.format(band_number), file=open(results_txt, \"a\"))\n",
    "print('---------------------------------------', file=open(results_txt, \"a\"))\n",
    "print('TRAINING', file=open(results_txt, \"a\"))\n",
    "print('Number of Trees: {}'.format(est), file=open(results_txt, \"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "bneZO374zh9x"
   },
   "outputs": [],
   "source": [
    "# laod training data from shape file\n",
    "# img_ds = gdal.Open(img_RS, gdal.GA_ReadOnly)\n",
    "\n",
    "#model_dataset = gdal.Open(model_raster_fname)\n",
    "shape_dataset = ogr.Open(training)\n",
    "shape_layer = shape_dataset.GetLayer()\n",
    "\n",
    "mem_drv = gdal.GetDriverByName('MEM')\n",
    "mem_raster = mem_drv.Create('',img_ds.RasterXSize,img_ds.RasterYSize,1,gdal.GDT_UInt16)\n",
    "#mem_raster.SetProjection(img_ds.GetProjection())\n",
    "mem_raster.SetGeoTransform(img_ds.GetGeoTransform())\n",
    "mem_band = mem_raster.GetRasterBand(1)\n",
    "mem_band.Fill(0)\n",
    "mem_band.SetNoDataValue(0)\n",
    "\n",
    "att_ = 'ATTRIBUTE='+attribute\n",
    "# http://gdal.org/gdal__alg_8h.html#adfe5e5d287d6c184aab03acbfa567cb1\n",
    "# http://gis.stackexchange.com/questions/31568/gdal-rasterizelayer-doesnt-burn-all-polygons-to-raster\n",
    "err = gdal.RasterizeLayer(mem_raster, [1], shape_layer, None, None, [1],  [att_,\"ALL_TOUCHED=TRUE\"])\n",
    "assert err == gdal.CE_None\n",
    "\n",
    "roi = mem_raster.ReadAsArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bneZO374zh9x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1365662 training samples\n",
      "training data include 6 classes: [1 2 3 4 5 6]\n",
      "Our X matrix is sized: (1365662, 142)\n",
      "Our y array is sized: (1365662,)\n"
     ]
    }
   ],
   "source": [
    "# # Display images\n",
    "# plt.subplot(121)\n",
    "# plt.imshow(img[:, :, 0], cmap=plt.cm.Greys_r)\n",
    "# plt.title('RS image - first band')\n",
    "\n",
    "# plt.subplot(122)\n",
    "# plt.imshow(roi, cmap=plt.cm.Spectral)\n",
    "# plt.title('Training Image')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# Number of training pixels:\n",
    "n_samples = (roi > 0).sum()\n",
    "print('{n} training samples'.format(n=n_samples))\n",
    "print('{n} training samples'.format(n=n_samples), file=open(results_txt, \"a\"))\n",
    "\n",
    "# What are our classification labels?\n",
    "labels = np.unique(roi[roi > 0])\n",
    "print('training data include {n} classes: {classes}'.format(n=labels.size, classes=labels))\n",
    "print('training data include {n} classes: {classes}'.format(n=labels.size, classes=labels), file=open(results_txt, \"a\"))\n",
    "\n",
    "# Subset the image dataset with the training image = X\n",
    "# Mask the classes on the training dataset = y\n",
    "# These will have n_samples rows\n",
    "X = img[roi > 0, :]\n",
    "y = roi[roi > 0]\n",
    "\n",
    "print('Our X matrix is sized: {sz}'.format(sz=X.shape))\n",
    "print('Our y array is sized: {sz}'.format(sz=y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "bneZO374zh9x"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend ThreadingBackend with 60 concurrent workers.\n",
      "[Parallel(n_jobs=60)]: Done  80 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=60)]: Done 330 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=60)]: Done 500 out of 500 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model pickled\n",
      "OOB prediction of accuracy is: 99.89829108520264%\n",
      "Band 1 importance: 0.04873391072799345\n",
      "Band 2 importance: 0.03712309958480305\n",
      "Band 3 importance: 0.06025347585026408\n",
      "Band 4 importance: 0.08660103331267174\n",
      "Band 5 importance: 0.032994143186208226\n",
      "Band 6 importance: 0.00329717645630164\n",
      "Band 7 importance: 0.003206364092673925\n",
      "Band 8 importance: 0.0038033147262143256\n",
      "Band 9 importance: 0.005096514784306885\n",
      "Band 10 importance: 0.0030858019407007517\n",
      "Band 11 importance: 0.004227307270155918\n",
      "Band 12 importance: 0.00425202311187604\n",
      "Band 13 importance: 0.00802269846514062\n",
      "Band 14 importance: 0.008263153592630867\n",
      "Band 15 importance: 0.007779800827184584\n",
      "Band 16 importance: 0.004693919248624135\n",
      "Band 17 importance: 0.0017158241759222944\n",
      "Band 18 importance: 0.0016881487656685535\n",
      "Band 19 importance: 0.002624760076733234\n",
      "Band 20 importance: 0.002158330895970496\n",
      "Band 21 importance: 0.001611023303517178\n",
      "Band 22 importance: 0.005342572924733339\n",
      "Band 23 importance: 0.004261780774454814\n",
      "Band 24 importance: 0.00548059867716561\n",
      "Band 25 importance: 0.005160088853522369\n",
      "Band 26 importance: 0.0043659485527865515\n",
      "Band 27 importance: 0.0032943710532706808\n",
      "Band 28 importance: 0.003260969553785364\n",
      "Band 29 importance: 0.003030875433912416\n",
      "Band 30 importance: 0.00432840913343372\n",
      "Band 31 importance: 0.010117906559499271\n",
      "Band 32 importance: 0.004289527686389623\n",
      "Band 33 importance: 0.002063594041269183\n",
      "Band 34 importance: 0.005755743974488883\n",
      "Band 35 importance: 0.00572520962191103\n",
      "Band 36 importance: 0.008440304988771801\n",
      "Band 37 importance: 0.018372546592138706\n",
      "Band 38 importance: 0.004139714697507605\n",
      "Band 39 importance: 0.0022320446927215666\n",
      "Band 40 importance: 0.010343756549786077\n",
      "Band 41 importance: 0.011394965703131098\n",
      "Band 42 importance: 0.011679447391054597\n",
      "Band 43 importance: 0.0017747827204110122\n",
      "Band 44 importance: 0.0024260814666983133\n",
      "Band 45 importance: 0.005114721633327848\n",
      "Band 46 importance: 0.002694163480211568\n",
      "Band 47 importance: 0.003048869275601345\n",
      "Band 48 importance: 0.0025902264705516443\n",
      "Band 49 importance: 0.0024102491364826092\n",
      "Band 50 importance: 0.0025207387754338922\n",
      "Band 51 importance: 0.0058734624312491825\n",
      "Band 52 importance: 0.0012490098595940096\n",
      "Band 53 importance: 0.0029956480094337707\n",
      "Band 54 importance: 0.003044522148005987\n",
      "Band 55 importance: 0.0075507592195768695\n",
      "Band 56 importance: 0.0031386790516017174\n",
      "Band 57 importance: 0.005544423649189091\n",
      "Band 58 importance: 0.006185407028495689\n",
      "Band 59 importance: 0.004128794267172195\n",
      "Band 60 importance: 0.007870013718333551\n",
      "Band 61 importance: 0.002195857926444279\n",
      "Band 62 importance: 0.0036192483974110206\n",
      "Band 63 importance: 0.0018354371453442487\n",
      "Band 64 importance: 0.0028297859052310225\n",
      "Band 65 importance: 0.0024764138265954264\n",
      "Band 66 importance: 0.0025029559921001935\n",
      "Band 67 importance: 0.0033983299625686626\n",
      "Band 68 importance: 0.005635686104843983\n",
      "Band 69 importance: 0.004145120957646113\n",
      "Band 70 importance: 0.005470809390880888\n",
      "Band 71 importance: 0.0031890930057722616\n",
      "Band 72 importance: 0.005183493153482618\n",
      "Band 73 importance: 0.004980776242132402\n",
      "Band 74 importance: 0.004205622648108011\n",
      "Band 75 importance: 0.004260467300933266\n",
      "Band 76 importance: 0.0035263012179378114\n",
      "Band 77 importance: 0.0034303086930635687\n",
      "Band 78 importance: 0.0030526576796451586\n",
      "Band 79 importance: 0.0028835729014323602\n",
      "Band 80 importance: 0.004382809862741114\n",
      "Band 81 importance: 0.003192718546254188\n",
      "Band 82 importance: 0.002967385567333396\n",
      "Band 83 importance: 0.002184864558878033\n",
      "Band 84 importance: 0.023188502724707044\n",
      "Band 85 importance: 0.023644137821634565\n",
      "Band 86 importance: 0.027252271792145823\n",
      "Band 87 importance: 0.0022949737630603546\n",
      "Band 88 importance: 0.0026504947830002785\n",
      "Band 89 importance: 0.0039583310266767925\n",
      "Band 90 importance: 0.00418176080086231\n",
      "Band 91 importance: 0.0037439317282809016\n",
      "Band 92 importance: 0.004976778668345272\n",
      "Band 93 importance: 0.003685614334566986\n",
      "Band 94 importance: 0.006195284925336067\n",
      "Band 95 importance: 0.00680702225084446\n",
      "Band 96 importance: 0.006532772672688822\n",
      "Band 97 importance: 0.004171141254434228\n",
      "Band 98 importance: 0.00266072368937655\n",
      "Band 99 importance: 0.005998223821778927\n",
      "Band 100 importance: 0.0014674221680694866\n",
      "Band 101 importance: 0.003992959787608231\n",
      "Band 102 importance: 0.004397811613134468\n",
      "Band 103 importance: 0.004865794482321602\n",
      "Band 104 importance: 0.004473565480002295\n",
      "Band 105 importance: 0.005887259897977086\n",
      "Band 106 importance: 0.0050497551584229574\n",
      "Band 107 importance: 0.0035541254489142877\n",
      "Band 108 importance: 0.00353313553659932\n",
      "Band 109 importance: 0.003082072005547666\n",
      "Band 110 importance: 0.006570984293783073\n",
      "Band 111 importance: 0.007236443529075331\n",
      "Band 112 importance: 0.0075299745763308425\n",
      "Band 113 importance: 0.0034000128724739932\n",
      "Band 114 importance: 0.00805556108761914\n",
      "Band 115 importance: 0.0044594501589421045\n",
      "Band 116 importance: 0.012156213450000605\n",
      "Band 117 importance: 0.008939489649159013\n",
      "Band 118 importance: 0.0064200917821991945\n",
      "Band 119 importance: 0.005689946236075051\n",
      "Band 120 importance: 0.007128128163321279\n",
      "Band 121 importance: 0.0059661313041591245\n",
      "Band 122 importance: 0.006300398599507071\n",
      "Band 123 importance: 0.006843130236175357\n",
      "Band 124 importance: 0.00795296466201636\n",
      "Band 125 importance: 0.0037229245663243766\n",
      "Band 126 importance: 0.0038351111722150395\n",
      "Band 127 importance: 0.004467183589533513\n",
      "Band 128 importance: 0.005587987845631855\n",
      "Band 129 importance: 0.009961291145056774\n",
      "Band 130 importance: 0.004205774910592702\n",
      "Band 131 importance: 0.002823555216114955\n",
      "Band 132 importance: 0.0033877298879229152\n",
      "Band 133 importance: 0.009012953814169024\n",
      "Band 134 importance: 0.008226688190977797\n",
      "Band 135 importance: 0.008739475718936062\n",
      "Band 136 importance: 0.005732233378069412\n",
      "Band 137 importance: 0.007628674159025755\n",
      "Band 138 importance: 0.0030709909091219995\n",
      "Band 139 importance: 0.003301122160606025\n",
      "Band 140 importance: 0.0038108815439753265\n",
      "Band 141 importance: 0.006534530977665491\n",
      "Band 142 importance: 0.013033631397440024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend ThreadingBackend with 60 concurrent workers.\n",
      "[Parallel(n_jobs=60)]: Done  80 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=60)]: Done 330 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=60)]: Done 500 out of 500 | elapsed:    7.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict       1       2       3       4       5      6      All\n",
      "truth                                                          \n",
      "1        755987       0       0       0       0      0   755987\n",
      "2             0  154516       0       0       0      0   154516\n",
      "3             0       0  165898       0       0      0   165898\n",
      "4             0       0       0  157128       0      0   157128\n",
      "5             0       0       0       0  119225      0   119225\n",
      "6             0       0       0       0       0  12908    12908\n",
      "All      755987  154516  165898  157128  119225  12908  1365662\n",
      "Reshaped from (12434, 13246, 142) to (164700764, 142)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=est, oob_score=True, verbose=1, n_jobs=n_cores)\n",
    "\n",
    "# verbose = 2 -> prints out every tree progression\n",
    "# rf = RandomForestClassifier(n_estimators=est, oob_score=True, verbose=2, n_jobs=n_cores)\n",
    "\n",
    "\n",
    "\n",
    "X = np.nan_to_num(X)\n",
    "rf2 = rf.fit(X, y)\n",
    "\n",
    "\n",
    "# Save the trained model to a file\n",
    "pickle_file = '/work/pi_cschweik_umass_edu/Ryan/Classification_products/OTH_all_reclass_classification_v4_s2.pkl'\n",
    "\n",
    "with open(pickle_file, 'wb') as file:\n",
    "    pickle.dump(rf2, file)\n",
    "\n",
    "print ('model pickled')\n",
    "\n",
    "# With our Random Forest model fit, we can check out the \"Out-of-Bag\" (OOB) prediction score:\n",
    "\n",
    "print('--------------------------------', file=open(results_txt, \"a\"))\n",
    "print('TRAINING and RF Model Diagnostics:', file=open(results_txt, \"a\"))\n",
    "print('OOB prediction of accuracy is: {oob}%'.format(oob=rf.oob_score_ * 100))\n",
    "print('OOB prediction of accuracy is: {oob}%'.format(oob=rf.oob_score_ * 100), file=open(results_txt, \"a\"))\n",
    "\n",
    "\n",
    "# we can show the band importance:\n",
    "bands = range(1,img_ds.RasterCount+1)\n",
    "\n",
    "for b, imp in zip(bands, rf2.feature_importances_):\n",
    "    print('Band {b} importance: {imp}'.format(b=b, imp=imp))\n",
    "    print('Band {b} importance: {imp}'.format(b=b, imp=imp), file=open(results_txt, \"a\"))\n",
    "\n",
    "    \n",
    "# Let's look at a crosstabulation to see the class confusion. \n",
    "# To do so, we will import the Pandas library for some help:\n",
    "# Setup a dataframe -- just like R\n",
    "# Exception Handling because of possible Memory Error\n",
    "\n",
    "try:\n",
    "    df = pd.DataFrame()\n",
    "    df['truth'] = y\n",
    "    df['predict'] = rf.predict(X)\n",
    "\n",
    "except MemoryError:\n",
    "    print('Crosstab not available ')\n",
    "\n",
    "else:\n",
    "    # Cross-tabulate predictions\n",
    "    print(pd.crosstab(df['truth'], df['predict'], margins=True))\n",
    "    print(pd.crosstab(df['truth'], df['predict'], margins=True), file=open(results_txt, \"a\"))\n",
    "    \n",
    "# Predicting the rest of the image\n",
    "\n",
    "# generate mask image from red band\n",
    "mask = np.copy(img[:,:,0])\n",
    "mask[mask > 0.0] = 1.0 # all actual pixels have a value of 1.0\n",
    "\n",
    "# Take our full image and reshape into long 2d array (nrow * ncol, nband) for classification\n",
    "old_shape = img.shape\n",
    "new_shape = (img.shape[0] * img.shape[1], img.shape[2])\n",
    "# img = img[:, :, :int(img.shape[2])].reshape(new_shape)\n",
    "img = img.reshape(new_shape)\n",
    "\n",
    "print('Reshaped from {o} to {n}'.format(o=old_shape, n=img.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "vrB7XKyDr3LH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "# img = np.nan_to_num(img)\n",
    "img[np.isnan(img)] = 0.0\n",
    "# class_prediction = rf.predict(img)\n",
    "\n",
    "print (\"DONE!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hp8gwSplB0LJ"
   },
   "source": [
    "# **Apply Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "z4Sry-DPcVpQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend ThreadingBackend with 60 concurrent workers.\n",
      "[Parallel(n_jobs=60)]: Done  80 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=60)]: Done 330 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=60)]: Done 500 out of 500 | elapsed:   34.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.999999878567655 %, derzeit: 8235038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend ThreadingBackend with 60 concurrent workers.\n",
      "[Parallel(n_jobs=60)]: Done  80 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=60)]: Done 330 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=60)]: Done 500 out of 500 | elapsed:   35.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.99999975713531 %, derzeit: 16470076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend ThreadingBackend with 60 concurrent workers.\n",
      "[Parallel(n_jobs=60)]: Done  80 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=60)]: Done 330 tasks      | elapsed:   23.7s\n",
      "[Parallel(n_jobs=60)]: Done 500 out of 500 | elapsed:   33.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.999999635702965 %, derzeit: 24705114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend ThreadingBackend with 60 concurrent workers.\n",
      "[Parallel(n_jobs=60)]: Done  80 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=60)]: Done 330 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=60)]: Done 500 out of 500 | elapsed:   38.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.99999951427062 %, derzeit: 32940152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend ThreadingBackend with 60 concurrent workers.\n",
      "[Parallel(n_jobs=60)]: Done  80 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=60)]: Done 330 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=60)]: Done 500 out of 500 | elapsed:   37.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.999999392838276 %, derzeit: 41175190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend ThreadingBackend with 60 concurrent workers.\n",
      "[Parallel(n_jobs=60)]: Done  80 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=60)]: Done 330 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=60)]: Done 500 out of 500 | elapsed:   37.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.99999927140593 %, derzeit: 49410228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend ThreadingBackend with 60 concurrent workers.\n",
      "[Parallel(n_jobs=60)]: Done  80 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=60)]: Done 330 tasks      | elapsed:   27.2s\n",
      "[Parallel(n_jobs=60)]: Done 500 out of 500 | elapsed:   38.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.99999914997358 %, derzeit: 57645266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend ThreadingBackend with 60 concurrent workers.\n",
      "[Parallel(n_jobs=60)]: Done  80 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=60)]: Done 330 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=60)]: Done 500 out of 500 | elapsed:   39.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.99999902854124 %, derzeit: 65880304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend ThreadingBackend with 60 concurrent workers.\n",
      "[Parallel(n_jobs=60)]: Done  80 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=60)]: Done 330 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=60)]: Done 500 out of 500 | elapsed:   38.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.999998907108896 %, derzeit: 74115342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend ThreadingBackend with 60 concurrent workers.\n",
      "[Parallel(n_jobs=60)]: Done  80 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=60)]: Done 330 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=60)]: Done 500 out of 500 | elapsed:   41.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.99999878567655 %, derzeit: 82350380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend ThreadingBackend with 60 concurrent workers.\n",
      "[Parallel(n_jobs=60)]: Done  80 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=60)]: Done 330 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=60)]: Done 500 out of 500 | elapsed:   40.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.9999986642442 %, derzeit: 90585418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend ThreadingBackend with 60 concurrent workers.\n",
      "[Parallel(n_jobs=60)]: Done  80 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=60)]: Done 330 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=60)]: Done 500 out of 500 | elapsed:   40.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.99999854281186 %, derzeit: 98820456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend ThreadingBackend with 60 concurrent workers.\n",
      "[Parallel(n_jobs=60)]: Done  80 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=60)]: Done 330 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=60)]: Done 500 out of 500 | elapsed:   38.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.99999842137952 %, derzeit: 107055494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend ThreadingBackend with 60 concurrent workers.\n",
      "[Parallel(n_jobs=60)]: Done  80 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=60)]: Done 330 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=60)]: Done 500 out of 500 | elapsed:   37.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.99999829994717 %, derzeit: 115290532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend ThreadingBackend with 60 concurrent workers.\n",
      "[Parallel(n_jobs=60)]: Done  80 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=60)]: Done 330 tasks      | elapsed:   28.2s\n",
      "[Parallel(n_jobs=60)]: Done 500 out of 500 | elapsed:   39.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.99999817851483 %, derzeit: 123525570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend ThreadingBackend with 60 concurrent workers.\n",
      "[Parallel(n_jobs=60)]: Done  80 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=60)]: Done 330 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=60)]: Done 500 out of 500 | elapsed:   36.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.99999805708248 %, derzeit: 131760608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend ThreadingBackend with 60 concurrent workers.\n",
      "[Parallel(n_jobs=60)]: Done  80 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=60)]: Done 330 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=60)]: Done 500 out of 500 | elapsed:   38.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.99999793565013 %, derzeit: 139995646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend ThreadingBackend with 60 concurrent workers.\n",
      "[Parallel(n_jobs=60)]: Done  80 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=60)]: Done 330 tasks      | elapsed:   27.0s\n",
      "[Parallel(n_jobs=60)]: Done 500 out of 500 | elapsed:   37.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.99999781421779 %, derzeit: 148230684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend ThreadingBackend with 60 concurrent workers.\n",
      "[Parallel(n_jobs=60)]: Done  80 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=60)]: Done 330 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=60)]: Done 500 out of 500 | elapsed:   35.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.99999769278544 %, derzeit: 156465722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Using backend ThreadingBackend with 60 concurrent workers.\n",
      "[Parallel(n_jobs=60)]: Done  80 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=60)]: Done 330 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=60)]: Done 500 out of 500 | elapsed:   34.5s finished\n",
      "[Parallel(n_jobs=60)]: Using backend ThreadingBackend with 60 concurrent workers.\n",
      "[Parallel(n_jobs=60)]: Done  80 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=60)]: Done 330 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.9999975713531 %, derzeit: 164700760\n",
      "Class prediction was successful without slicing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=60)]: Done 500 out of 500 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped back to (12434, 13246)\n",
      "Image saved to: /work/pi_cschweik_umass_edu/Ryan/Classification_products/OTH_all_reclass_classification_v4_s2.gtif\n"
     ]
    }
   ],
   "source": [
    "\n",
    "slices = int(round(len(img)/20))\n",
    "\n",
    "test = True\n",
    "\n",
    "while test == True:\n",
    "    try:\n",
    "        class_preds = list()\n",
    "\n",
    "        temp = rf.predict(img[0:slices+1,:])\n",
    "        class_preds.append(temp)\n",
    "\n",
    "        for i in range(slices,len(img),slices):\n",
    "            print('{} %, derzeit: {}'.format((i*100)/(len(img)), i))\n",
    "            temp = rf.predict(img[i+1:i+(slices+1),:])                \n",
    "            class_preds.append(temp)\n",
    "\n",
    "    except MemoryError as error:\n",
    "        slices = slices/4\n",
    "        print('Not enought RAM, new slices = {}'.format(slices))\n",
    "\n",
    "    else:\n",
    "        test = False\n",
    "else:\n",
    "    print('Class prediction was successful without slicing!')\n",
    "#concatenate all slices and re-shape it to the original extend\n",
    "try:\n",
    "    class_prediction = np.concatenate(class_preds,axis = 0)\n",
    "except NameError:\n",
    "    print('No slicing was necessary!')\n",
    "    \n",
    "class_prediction = class_prediction.reshape(old_shape[:2])\n",
    "print('Reshaped back to {}'.format(class_prediction.shape))\n",
    "\n",
    "\n",
    "# # generate mask image from red band\n",
    "# mask = np.copy(img[:,:,0])\n",
    "# mask[mask > 0.0] = 1.0 # all actual pixels have a value of 1.0\n",
    "\n",
    "# plot mask\n",
    "\n",
    "# plt.imshow(mask)\n",
    "\n",
    "# mask classification an plot\n",
    "\n",
    "class_prediction.astype(np.float16)\n",
    "class_prediction_ = class_prediction*mask\n",
    "\n",
    "cols = class_prediction.shape[1]\n",
    "rows = class_prediction.shape[0]\n",
    "\n",
    "class_prediction_.astype(np.float16)\n",
    "\n",
    "driver = gdal.GetDriverByName(\"gtiff\")\n",
    "outdata = driver.Create(classification_image, cols, rows, 1, gdal.GDT_UInt16)\n",
    "outdata.SetGeoTransform(img_ds.GetGeoTransform())##sets same geotransform as input\n",
    "outdata.SetProjection(img_ds.GetProjection())##sets same projection as input\n",
    "outdata.GetRasterBand(1).WriteArray(class_prediction_)\n",
    "outdata.FlushCache() ##saves to disk!!\n",
    "del outdata\n",
    "print('Image saved to: {}'.format(classification_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Salt Marsh",
   "language": "python",
   "name": "salt_marsh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
