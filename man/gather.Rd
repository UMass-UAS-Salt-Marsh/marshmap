% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gather.R
\name{gather}
\alias{gather}
\title{Collect raster data for each site}
\usage{
gather(
  site = NULL,
  pattern = "",
  update = TRUE,
  replace = FALSE,
  check = FALSE
)
}
\arguments{
\item{site}{one or more site names, using 3 letter abbreviation. Default = all sites}

\item{pattern}{regex filtering rasters, case-insensitive. Default = "" (match all). Note: only files ending in \code{.tif} are included in any case.
Examples:
\itemize{
\item to match all Mica orthophotos, use \code{mica_orth}
\item to match all Mica files from July, use \code{Jun.*mica}
\item to match Mica files for a series of dates, use \verb{11nov20.*mica|14oct20.*mica}
}}

\item{update}{if TRUE, only process new files, assuming existing files are good}

\item{replace}{if TRUE, deletes the existing stack and replaces it. Use with care!}

\item{check}{if TRUE, just check to see that source directories and files exist, but don't cache or process anything}
}
\description{
Clip to site boundary, resample and align to standard resolution. Data will be copied from various source
locations (orthophotos, DEMs, canopy height models).
}
\details{
Additional parameters, set in \code{pars.yml} (see \code{\link[=init]{init()}}):
\itemize{
\item \code{subdirs} subdirectories to search, ending with slash. Default = orthos, DEMs, and canopy height models (okay to include empty or
nonexistent directories). Use \verb{\\<site>} in subdirectories that include a site name, e.g., \verb{\\<site> Share/Photogrammetry DEMs}.
WARNING: paths on the Google Drive are case-sensitive!
\item \code{basedir} full path to parameter and data directories
\item \code{resultbase} base name of result directory
\item \code{resultdir} subdirectory for results. Default is \verb{stacked/}. The site name will be appended to this.
\item \code{sftp} list(url = address of site, user = credentials). Credentials are either \code{username:password} or \verb{*filename} with username:password. Make sure
to include credential files in \code{.gitignore} and \code{.Rbuildignore} so it doesn't end up out in the world!
\item \code{cachedir} path to local cache directory; required when \code{sourcedrive = google} or \code{sftp}. The cache directory should be larger than the total amount of
data processed--this code isn't doing any quota management. This is not an issue when using a
\href{https://docs.unity.rc.umass.edu/documentation/managing-files/hpc-workspace/}{scratch drive on Unity}, as the limit is 50 TB.
There's no great need to carry over cached data over long periods, as downloading from Google or SFTP to Unity is very fast.
Be polite and release the scratch workspace when you're done. See comments in \code{\link[=get_file]{get_file()}} for more notes on caching.
\item \code{sourcedrive} one of \code{local}, \code{google}, \code{sftp}
\itemize{
\item \code{local} - read source from local drive
\item \code{google} - get source data from currently connected Google Drive (login via browser on first connection) and cache it locally. Must set \code{cachedir} option.
\item \code{sftp} - get source data from SFTP site. Must set \code{sftp} and \code{cachedir} options.
}
}

Source data:
\itemize{
\item geoTIFFs for each site
\item pars/sites.txt    table of site abbreviation, site name, footprint shapefile, raster standard
}

Results:
\itemize{
\item geoTIFFs, clipped, resampled, and aligned   *** Make sure you've closed ArcGIS/QGIS projects that point to these before running! ***
\item gather_data.log, in xxxxxx
}

All source data are expected to be in \code{EPSG:4326}. Non-conforming rasters will be reprojected.

\code{sites.txt} must include the name of the footprint shapefile for each site.

\code{sites.txt} must include a standard geoTIFF for each site, to be used as the standard for grain and alignment; all rasters will be
resampled to match. Standards MUST be in the standard projection, \code{EPSG:4326}. Use find_standards() to pick good candidates.

Note that adding to an existing stack using a different standard will lead to sorrow. \strong{BEST PRACTICE}: don't change the standards
in \code{standards.txt}; if you must change them, rerun with replace = TRUE to replace results that were created using the old standard.

Note that initial runs with Google Drive in a session open the browser for authentication or wait for input from the console, so
don't run blindly when using the Google Drive

Remember that some SFTP servers require connection via VPN

********************* Hanging issues for SFTP:
\itemize{
\item SFTP implementations behave differently so I'll have to revise once the NAS is up and running.
\item Windows dates are a mess for DST. Hopefully Linux won't be.
}

Example runs:

Complete for all sites:

\if{html}{\out{<div class="sourceCode">}}\preformatted{  `gather_data()`
}\if{html}{\out{</div>}}

Run for 2 sites, low tide only:

\if{html}{\out{<div class="sourceCode">}}\preformatted{  `gather_data(site = c('oth', 'wes'), pattern = '_low_')`
}\if{html}{\out{</div>}}

See end of this function for more example calls
}
