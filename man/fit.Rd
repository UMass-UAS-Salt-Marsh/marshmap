% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fit.R
\name{fit}
\alias{fit}
\title{Build statistical models of vegetation cover}
\usage{
fit(
  site = NULL,
  datafile = "data",
  name = "",
  method = "rf",
  fitargs = NULL,
  vars = "{*}",
  exclude_vars = "",
  exclude_classes = NULL,
  include_classes = NULL,
  exclude_years = NULL,
  min_class = 500,
  reclass = c(13, 2),
  max_samples = NULL,
  years = NULL,
  minscore = 0,
  maxmissing = 20,
  max_miss_train = 0.2,
  top_importance = 20,
  holdout = NULL,
  bypoly = "bypoly01",
  byyear = NULL,
  blocks = NULL,
  auc = FALSE,
  hyper = NULL,
  notune = FALSE,
  resources = NULL,
  local = FALSE,
  trap = TRUE,
  comment = NULL
)
}
\arguments{
\item{site}{Three letter site code, or vector of site names if fitting multiple sites}

\item{datafile}{Name of data file. It must be an \code{.RDS} file, but exclude the
extension. If fitting multiple sites, either use a single datafile name
shared among sites, or a vector matching site.}

\item{name}{Optional model name}

\item{method}{One of \code{rf} for Random Forest, \code{boost} for AdaBoost. Default = \code{rf}.}

\item{fitargs}{A named list of additional arguments to pass to the model (\code{ranger} or \code{boost})}

\item{vars}{Vector of variables to restrict analysis to. Default = \verb{\{*\}},
all variables. \code{vars} is processed by \code{find_orthos}, and may include file names,
portable names, search names and regular expressions of file and portable names.}

\item{exclude_vars}{An optional vector of variables to exclude. As with \code{vars}, variables
are processed by \code{find_orthos}}

\item{exclude_classes}{Numeric vector of subclasses to exclude. This overrides \code{fit_exclude}
that may be included in \code{sites.txt}.}

\item{include_classes}{Numeric vector of subclasses to include - all other classes are dropped.
\code{include_classes} overrides \code{fit_exclude} (in \code{sites.txt}) and \code{exclude_classes}.}

\item{exclude_years}{A vector of one or more years of ground truth data to exclude (requires a
year column in source data)}

\item{min_class}{Minimum number of training samples to allow in a class. All classes with
fewer samples in training set as well as all classes with zero cases in the
validation set will be dropped from the model. Use \code{min_class = NULL} to prevent
dropping any classes.}

\item{reclass}{Matrix or vector of paired classes to reclassify. Pass either a two column
matrix, such that values in the first column are reclassifed to the second column, or a
vector with pairs, \code{reclass = c(13, 2, 3, 4)}, which would reclassify all 13s to 2 and 3s to 4,
lumping each pair of classes. Reclassifying is not iterative, thus you could swap
1s and 2s with \code{reclass = c(1, 2, 2, 1)}, not that you'd want to.}

\item{max_samples}{Maximum number of samples to use - subsample if necessary}

\item{years}{Vector of years to restrict variables to}

\item{minscore}{Minimum score for orthos. Files with a minimum score of less than
this are excluded from results. Default is 0, but rejected orthos are always
excluded.}

\item{maxmissing}{Maximum percent missing in orthos. Files with percent missing greater
than this are excluded.}

\item{max_miss_train}{Maximum proportion of missing training points allowed before a
variable is dropped}

\item{top_importance}{Number of variables to keep for variable importance}

\item{holdout}{Proportion of points to hold out. For Random Forest, this specifies
the size of the single validation set, while for boosting, it is the size of each
of the testing and validation sets.}

\item{bypoly}{Polygons to treat as holdout data. Supply the name of a \code{bypoly} cross-validation
sequence in the sampled data. \code{gather} creates \code{bypoly01} through \code{bypoly05}, with sequences
of 1:10 for each subclass. Poly groups 1 and 6 will be used as holdouts. To specify different
groups, use \verb{blocks = list(block = 'bypoly01', classes = c(2, 7)}, for instance.}

\item{byyear}{One or more years to treat as holdout data. If supplied, this superceeds bypoly.}

\item{blocks}{An alternative to holding out random points. Specify a named list
with \verb{block = <name of block column>, classes = <vector of block classes to hold out>}.
Set this up by creating a shapefile corresponding to ground truth data with a variable
\code{block} that contains integer block classes, and placing it in the \verb{blocks/} directory
for the site. \code{gather} and \code{sample} will collect and process block data for you to
use here.}

\item{auc}{If TRUE, calculate class probabilities so we can calculate AUC}

\item{hyper}{Hyperparameters. \emph{\strong{To be defined.}}}

\item{notune}{If TRUE, don't do hyperparameter tuning. This can cost you a few percent
in CCR, but will speed the run up six-fold from the default.}

\item{resources}{Slurm launch resources. See \link[slurmcollie]{launch}.
These take priority over the function's defaults.}

\item{local}{If TRUE, run locally; otherwise, spawn a batch run on Unity}

\item{trap}{If TRUE, trap errors in local mode; if FALSE, use normal R error
handling. Use this for debugging. If you get unrecovered errors, the job
won't be added to the jobs database. Has no effect if local = FALSE.}

\item{comment}{Optional launch / slurmcollie comment}
}
\description{
Given one or more sites and a model specification, builds a model of vegetation
cover and report model assessment.
}
