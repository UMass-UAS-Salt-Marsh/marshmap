% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gather_data.R
\name{gather_data}
\alias{gather_data}
\title{Collect raster data from various source locations (orthophotos, DEMs, canopy height models) for each site}
\usage{
gather_data(
  site = NULL,
  pattern = "",
  subdirs = c("RFM Processing Inputs/Orthomosaics/", "[site] Share/Photogrammetry DEMs/",
    "[site] Share/Canopy Height Models/"),
  basedir = "UAS Data Collection/",
  resultbase = "c:/Work/etc/saltmarsh/data/",
  resultdir = "stacked/",
  update = TRUE,
  replace = FALSE,
  check = FALSE,
  sourcedrive = "google",
  sftp = NULL,
  cachedir = "/scratch3/workspace/bcompton_umass_edu-cache"
)
}
\arguments{
\item{site}{one or more site names, using 3 letter abbreviation. Default = all sites}

\item{pattern}{regex filtering rasters, case-insensitive. Default = '' (match all). Note: only files ending in .tif are included in any case.
Examples:
\itemize{
\item to match all Mica orthophotos, use `pattern = 'mica_orth'``
\item to match all Mica files from July, use \code{pattern = 'Jun.*mica'}
\item to match Mica files for a series of dates, use pattern = \code{'11nov20.*mica|14oct20.*mica'}
}}

\item{subdirs}{subdirectories to search, ending with slash. Default = orthos, DEMs, and canopy height models (okay to include empty or
nonexistent directories). Use \verb{'\[site]'} in subdirectories that include a site name, e.g., \verb{'\[site] Share/Photogrammetry DEMs'}.
WARNING: paths on the Google Drive are case-sensitive!}

\item{basedir}{full path to subdirs}

\item{resultbase}{base name of result directory}

\item{resultdir}{subdir for results. Default is 'stacked/'. The site name will be appended to this.}

\item{update}{if TRUE, only process new files, assumming existing files are good}

\item{replace}{if TRUE, deletes the existing stack and replaces it. Use with care!}

\item{check}{if TRUE, just check to see that source directories and files exist, but don't cache or process anything}

\item{sourcedrive}{one of 'local', 'google', 'sftp'
\itemize{
\item \code{'local'} - read source from local drive
\item \code{'google'} - get source data from currently connected Google Drive (login via browser on first connection) and cache it locally. Must set cachedir option.
\item \code{'sftp'} - get source data from sftp site. Must set sftp and cachedir options.
}}

\item{sftp}{list(url = address of site, user = credentials). Credentials are either 'username:password' or '\*filename' with username:password. Make sure
to include credential files in .gitignore and .Rbuildignore so it doesn't end up out in the world!}

\item{cachedir}{path to local cache directory; required when sourcedrive = 'google' or 'sftp'. The cache directory should be larger than the total amount of
data processed--this code isn't doing any quota management. This is not an issue when using a scratch drive on Unity, as the limit is 50 TB.
There's no great need to carry over cached data over long periods, as downloading from Google or SFTP to Unity is very fast.
To set up a scratch drive on Unity, see https://docs.unity.rc.umass.edu/documentation/managing-files/hpc-workspace/. Be polite and
release the scratch workspace when you're done. See comments in get_file.R for more notes on caching.}
}
\description{
Clip to site boundary, resample and align to standard resolution.
}
\details{
Source data:
\itemize{
\item geoTIFFs for each site
\item pars/sites.txt    table of site abbreviation, site name, footprint shapefile, raster standard
}

Results:
geoTIFFs, clipped, resampled, and aligned   *** Make sure you've closed ArcGIS/QGIS projects that point to these before running! ***
gather_data.log, in resultbase

All source data are expected to be in \code{EPSG:4326}. Non-conforming rasters will be reprojected.

\code{sites.txt} must include the name of the footprint shapefile for each site.

\code{sites.txt} must include a standard geoTIFF for each site, to be used as the standard for grain and alignment; all rasters will be
resampled to match. Standards MUST be in the standard projection, \code{EPSG:4326}. Use find_standards() to pick good candidates.

Note that adding to an existing stack using a different standard will lead to sorrow. BEST PRACTICE: don't change the standards
in \code{standards.txt}; if you must change them, rerun with replace = TRUE to replace results using the old standard.

Note that initial runs with Google Drive in a session open the browser for authentication or wait for input from the console, so
don't run blindly when using the Google Drive

Remember that some SFTP servers require connection via VPN

********************* Hanging issues for SFTP:
- SFTP implementations behave differently so I'll have to revise once the NAS is up and running.
- Windows dates are a mess for DST. Hopefully Linux won't be.

Example runs:
Complete for all sites:
\code{gather_data()}
Run for 2 sites, low tide only:
\code{gather_data(site = c('oth', 'wes'), pattern = '_low_')}
See end of this function for more example calls
}
