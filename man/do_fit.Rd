% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/do_fit.R
\name{do_fit}
\alias{do_fit}
\title{Fit models}
\usage{
do_fit(
  fitid,
  sites,
  name,
  method,
  fitargs,
  vars,
  exclude_vars,
  exclude_classes,
  include_classes,
  min_class,
  reclass,
  max_samples,
  years,
  minscore,
  maxmissing,
  max_miss_train,
  top_importance,
  holdout,
  bypoly,
  blocks,
  auc,
  hyper,
  notune,
  rep = NULL
)
}
\arguments{
\item{fitid}{Fit id in the fits database}

\item{sites}{Data frame with \code{site} (3 letter code), \code{site_name} (long name), and
\code{datafile} (resolved path and filename of datafile). Sites, paths, and filenames
are vetted by fit - there's no checking here.}

\item{name}{Optional model name}

\item{method}{One of \code{rf} for Random Forest, \code{boost} for AdaBoost. Default = \code{rf}.}

\item{fitargs}{A named list of additional arguments to pass to the model (\code{ranger} or \code{boost})}

\item{vars}{Vector of variables to restrict analysis to. Default = \verb{\{*\}},
all variables. \code{vars} is processed by \code{find_orthos}, and may include file names,
portable names, search names and regular expressions of file and portable names.}

\item{exclude_vars}{An optional vector of variables to exclude. As with \code{vars}, variables
are processed by \code{find_orthos}}

\item{exclude_classes}{Numeric vector of subclasses to exclude. This overrides \code{fit_exclude}
that may be included in \code{sites.txt}.}

\item{include_classes}{Numeric vector of subclasses to include - all other classes are dropped.
\code{include_classes} overrides \code{fit_exclude} (in \code{sites.txt}) and \code{exclude_classes}.}

\item{min_class}{Minimum number of training samples to allow in a class. All classes with
fewer samples in training set as well as all classes with zero cases in the
validation set will be dropped from the model. Use \code{min_class = NULL} to prevent
dropping any classes.}

\item{reclass}{Matrix or vector of paired classes to reclassify. Pass either a two column
matrix, such that values in the first column are reclassifed to the second column, or a
vector with pairs, \code{reclass = c(13, 2, 3, 4)}, which would reclassify all 13s to 2 and 3s to 4,
lumping each pair of classes. Reclassifying is not iterative, thus you could swap
1s and 2s with \code{reclass = c(1, 2, 2, 1)}, not that you'd want to.}

\item{max_samples}{Maximum number of samples to use - subsample if necessary}

\item{years}{Vector of years to restrict variables to}

\item{minscore}{Minimum score for orthos. Files with a minimum score of less than
this are excluded from results. Default is 0, but rejected orthos are always
excluded.}

\item{maxmissing}{Maximum percent missing in orthos. Files with percent missing greater
than this are excluded.}

\item{max_miss_train}{Maximum proportion of missing training points allowed before a
variable is dropped}

\item{top_importance}{Number of variables to keep for variable importance}

\item{holdout}{Proportion of points to hold out. For Random Forest, this specifies
the size of the single validation set, while for boosting, it is the size of each
of the testing and validation sets.}

\item{bypoly}{The name of a \code{bypoly} cross-validation sequence in the sampled data.
\code{gather} creates \code{bypoly01} through \code{bypoly05}, with sequences of 1:10 for each
subclass. Poly groups 1 and 6 will be used as holdouts. To specify different groups,
use \verb{blocks = list(block = 'bypoly01', classes = c(2, 7)}, for instance.}

\item{blocks}{An alternative to holding out random points. Specify a named list
with \verb{block = <name of block column>, classes = <vector of block classes to hold out>}.
Set this up by creating a shapefile corresponding to ground truth data with a variable
\code{block} that contains integer block classes, and placing it in the \verb{blocks/} directory
for the site. \code{gather} and \code{sample} will collect and process block data for you to
use here.}

\item{auc}{If TRUE, calculate class probabilities so we can calculate AUC}

\item{hyper}{Hyperparameters \emph{\strong{To be defined}}}

\item{notune}{If TRUE, don't do hyperparameter tuning. This can cost you a few percent
in CCR, but will speed the run up six-fold from the default.}

\item{rep}{Throwaway argument to make \code{slurmcollie} happy}
}
\description{
Fit models
}
