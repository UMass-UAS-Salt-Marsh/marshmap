<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Assess a model fit from validation data — assess • saltmarsh</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Assess a model fit from validation data — assess"><meta name="description" content="Provide a model assessment. Normally called by fit, but may be called separately for models applied to new sites."><meta property="og:description" content="Provide a model assessment. Normally called by fit, but may be called separately for models applied to new sites."></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">saltmarsh</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/UMass-UAS-Salt-Marsh/marshmap/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Assess a model fit from validation data</h1>
      <small class="dont-index">Source: <a href="https://github.com/UMass-UAS-Salt-Marsh/marshmap/blob/main/R/assess.R" class="external-link"><code>R/assess.R</code></a></small>
      <div class="d-none name"><code>assess.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Provide a model assessment. Normally called by <code>fit</code>, but may be called separately for models applied to new sites.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">assess</span><span class="op">(</span></span>
<span>  fitid <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  model <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  newdata <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  site <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  top_importance <span class="op">=</span> <span class="fl">20</span>,</span>
<span>  summary <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  confusion <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  importance <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  freq <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  quiet <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-fitid">fitid<a class="anchor" aria-label="anchor" href="#arg-fitid"></a></dt>
<dd><p>id of a model in the fits database. If using this, omit <code>model</code>, as the model info will be
extracted from the database.</p></dd>


<dt id="arg-model">model<a class="anchor" aria-label="anchor" href="#arg-model"></a></dt>
<dd><p>Only when called by do_fit; named list of:</p><dl><dt>fit</dt>
<dd><p>model fit object</p></dd>

<dt>confuse</dt>
<dd><p>Confusion matrix</p></dd>

<dt>nvalidate</dt>
<dd><p>Number of cases in validation set</p></dd>

<dt>id</dt>
<dd><p>Model id</p></dd>

<dt>name</dt>
<dd><p>Model name</p></dd>


</dl></dd>


<dt id="arg-newdata">newdata<a class="anchor" aria-label="anchor" href="#arg-newdata"></a></dt>
<dd><p>An alternate validation set (e.g., from a different site). Variables
must conform with the original dataset.</p></dd>


<dt id="arg-site">site<a class="anchor" aria-label="anchor" href="#arg-site"></a></dt>
<dd><p>One or more site names, for display only</p></dd>


<dt id="arg-top-importance">top_importance<a class="anchor" aria-label="anchor" href="#arg-top-importance"></a></dt>
<dd><p>Number of variables to keep for variable importance</p></dd>


<dt id="arg-summary">summary<a class="anchor" aria-label="anchor" href="#arg-summary"></a></dt>
<dd><p>Print model summary info if TRUE</p></dd>


<dt id="arg-confusion">confusion<a class="anchor" aria-label="anchor" href="#arg-confusion"></a></dt>
<dd><p>Print the confusion matrix and complete statistics if TRUE</p></dd>


<dt id="arg-importance">importance<a class="anchor" aria-label="anchor" href="#arg-importance"></a></dt>
<dd><p>Print variable importance if TRUE</p></dd>


<dt id="arg-freq">freq<a class="anchor" aria-label="anchor" href="#arg-freq"></a></dt>
<dd><p>Print empirical class frequency table (number of cases from training
and holdout data by class) if TRUE</p></dd>


<dt id="arg-quiet">quiet<a class="anchor" aria-label="anchor" href="#arg-quiet"></a></dt>
<dd><p>If TRUE, don't print anything; just silently return stuff</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>Invisibly, a named list of</p><dl><dt>confusion</dt>
<dd><p>Confusion matrix and complete statistics</p></dd>

<dt>importance</dt>
<dd><p>Variable importance data frame</p></dd>


</dl></div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>Called by <code>do_fit</code>, but also may be called by the user. Either provide <code>fitid</code> for
the model you want to assess (the normal approach), or <code>model</code>, a list with necessary
arguments (the approach used by <code>do_fit</code>, because the model is not yet in the database).
When you call <code>assess</code> from the console, the fits database is not updated with the new
assessment.</p>
<p>You may supply <code>newdata</code> to assess a model on sites different from what the model
was built on. <code>newdata</code> is a data frame that conforms to the data the model was
built on. (<em><strong>how exactly</strong></em>?)</p>
<p>Assessments are returned invisibly; by default, they are printed to the console.</p>
<p><strong>Explanations</strong></p>
<p><em><strong>1. Model info</strong></em></p><ul><li><p>Model fit id and name, if supplied</p></li>
<li><p>Number of variables fit</p></li>
<li><p>Sample size for training and validation holdout set. The confusion matrix and all statistics are
derived from the holdout set.</p></li>
<li><p>Correct classification rate, the percent of cases that were predicted correctly.</p></li>
<li><p>Kappa, a refined version of the CCR that takes the probability of chance agreement into account.</p></li>
</ul><p><em><strong>2. Confusion matrix</strong></em></p><ul><li><p>Shows which classification errors were made. Values falling on the diagonal were predicted correctly.</p></li>
</ul><p><em><strong>3. Overall statistics</strong></em></p><ul><li><p><em>Accuracy</em> is the correct classification rate (also known as CCR), the percent of cases that fall on
the diagonal in the confusion matrix.</p></li>
<li><p>The <em>No Information Rate</em> is the CCR you'd get if you always bet the majority class.</p></li>
<li><p><em>Kappa</em> is a refined version of the CCR that takes the probability of chance agreement into account.</p></li>
<li><p><em>McNemar's test</em> only applies to two-class data.</p></li>
</ul><p><em><strong>4. Statistics by class</strong></em></p><ul><li><p>Lists the following statistics for each of the subclasses.
These all scale from 0 to 1, with 1 generally indicating higher performance (except for prevalence,
detection rate, and detection prevalence).</p><ul><li><p><em>Precision</em>, the proportion of cases predicted to be in the class that actually were (true positives /
(true positives + false positives))</p></li>
<li><p><em>Recall</em>, the proportion of cases actually in the class that were predicted to be in the class (true positives /
(true positives + false negatives))</p></li>
<li><p><em>F1</em>, the harmonic mean of precision and recall; a combined metric of model performance</p></li>
<li><p><em>Prevalence</em>, the proportion of all cases that are in this class</p></li>
<li><p><em>Detection Rate</em>, the proportion of all cases that are correctly predicted to be in this class</p></li>
<li><p><em>Detection Prevalence</em>, the proportion of all cases predicted to be in this class</p></li>
<li><p><em>Balanced Accuracy</em>, mean of true positive rate and true negative rate; a combined metric of model performance</p></li>
<li><p><em>AUC</em> (Area Under the Curve) is the probability that the model, for a particular class, when given a
random case in the class and a random case from another class, will rate the case in the class higher.
Unlike the other statistics, AUC is independent of the particular cutpoint chosen, and is telling us
about the performance of the probabilities produced by the model.</p></li>
</ul></li>
</ul><p><em><strong>5. Variable importance</strong></em></p><ul><li><p>Scaled from 0 to 100, gives the relative contribution of each variable to the model fit.
Less-important variables will be trimmed based on the top_importance option.
Note that variables are imagery bands, not an entire orthoimage; thus, for
instance, an RGB true color image represents three variables, any of which
may come into the model separately.</p></li>
</ul></div>

  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Bradley Compton.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer></div>





  </body></html>

