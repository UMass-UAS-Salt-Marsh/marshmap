<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Gather and prepare GIS data from data sources — gather • saltmarsh</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Gather and prepare GIS data from data sources — gather"><meta name="description" content="Gather raster and vector data from the source (either Google Drive or SFTP), and clip to site
boundary, resample and align to standard resolution. Data will be copied from various source
locations (orthophotos, DEMs, canopy height models). Robust to crashes and interruptions: cached
datasets that are fully downloaded will be used over re-downloading, and processed rasters won't be
re-processed unless update = TRUE or replace = TRUE."><meta property="og:description" content="Gather raster and vector data from the source (either Google Drive or SFTP), and clip to site
boundary, resample and align to standard resolution. Data will be copied from various source
locations (orthophotos, DEMs, canopy height models). Robust to crashes and interruptions: cached
datasets that are fully downloaded will be used over re-downloading, and processed rasters won't be
re-processed unless update = TRUE or replace = TRUE."></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">saltmarsh</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/UMass-UAS-Salt-Marsh/salt-marsh-mapping/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Gather and prepare GIS data from data sources</h1>
      <small class="dont-index">Source: <a href="https://github.com/UMass-UAS-Salt-Marsh/salt-marsh-mapping/blob/main/R/gather.R" class="external-link"><code>R/gather.R</code></a></small>
      <div class="d-none name"><code>gather.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Gather raster and vector data from the source (either Google Drive or SFTP), and clip to site
boundary, resample and align to standard resolution. Data will be copied from various source
locations (orthophotos, DEMs, canopy height models). Robust to crashes and interruptions: cached
datasets that are fully downloaded will be used over re-downloading, and processed rasters won't be
re-processed unless <code>update = TRUE</code> or <code>replace = TRUE</code>.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">gather</span><span class="op">(</span></span>
<span>  <span class="va">site</span>,</span>
<span>  pattern <span class="op">=</span> <span class="st">""</span>,</span>
<span>  update <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  check <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  field <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  resources <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  local <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  trap <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  comment <span class="op">=</span> <span class="cn">NULL</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-site">site<a class="anchor" aria-label="anchor" href="#arg-site"></a></dt>
<dd><p>One or more site names, using 3 letter abbreviation. Use <code>all</code> to process all sites.
In batch mode, each named site will be run in a separate job.</p></dd>


<dt id="arg-pattern">pattern<a class="anchor" aria-label="anchor" href="#arg-pattern"></a></dt>
<dd><p>Regex filtering rasters, case-insensitive. Default = "" (match all). Note: only
files ending in <code>.tif</code> are included in any case.
Examples:</p><ul><li><p>to match all Mica orthophotos, use <code>mica_orth</code></p></li>
<li><p>to match all Mica files from July, use <code>Jun.*mica</code></p></li>
<li><p>to match Mica files for a series of dates, use <code>11nov20.*mica|14oct20.*mica</code></p></li>
</ul></dd>


<dt id="arg-update">update<a class="anchor" aria-label="anchor" href="#arg-update"></a></dt>
<dd><p>If TRUE, only process new files, assuming existing files are good; otherwise,
process all files and replace existing ones.</p></dd>


<dt id="arg-check">check<a class="anchor" aria-label="anchor" href="#arg-check"></a></dt>
<dd><p>If TRUE, just check to see that source directories and files exist, but don't
cache or process anything</p></dd>


<dt id="arg-field">field<a class="anchor" aria-label="anchor" href="#arg-field"></a></dt>
<dd><p>If TRUE, download and process the field transects if they don't already exist.
The shapefile is downloaded for reference, and a raster corresponding to <code>standard</code> is created.</p></dd>


<dt id="arg-resources">resources<a class="anchor" aria-label="anchor" href="#arg-resources"></a></dt>
<dd><p>Slurm launch resources. See <a href="https://rdrr.io/pkg/slurmcollie/man/launch.html" class="external-link">launch</a>. These take priority
#'    over the function's defaults.</p></dd>


<dt id="arg-local">local<a class="anchor" aria-label="anchor" href="#arg-local"></a></dt>
<dd><p>If TRUE, run locally; otherwise, spawn a batch run on Unity</p></dd>


<dt id="arg-trap">trap<a class="anchor" aria-label="anchor" href="#arg-trap"></a></dt>
<dd><p>If TRUE, trap errors in local mode; if FALSE, use normal R error handling. Use this
for debugging. If you get unrecovered errors, the job won't be added to the jobs database. Has
no effect if local = FALSE.</p></dd>


<dt id="arg-comment">comment<a class="anchor" aria-label="anchor" href="#arg-comment"></a></dt>
<dd><p>Optional slurmcollie comment</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>Additional parameters, set in the <code>gather</code> block in <code>pars.yml</code> (see <code><a href="init.html">init()</a></code>):</p><ul><li><p><code>sourcedrive</code> one of <code>local</code>, <code>google</code>, <code>sftp</code></p><ul><li><p><code>local</code> - read source from local drive</p></li>
<li><p><code>google</code> - get source data from currently connected Google Drive (login via browser on first connection)
and cache it locally. Must set <code>cachedir</code> option.</p></li>
<li><p><code>sftp</code> - get source data from SFTP site. Must set <code>sftp</code> and <code>cachedir</code> options.</p></li>
</ul></li>
<li><p><code>sourcedir</code> directory with source rasters, generally on Google Drive or SFTP site</p></li>
<li><p><code>subdirs</code> subdirectories to search, ending with slash. Default = orthos, DEMs, and canopy height models (okay
to include empty or nonexistent directories). Use <code>&lt;site&gt;</code> in subdirectories that include a site name, e.g.,
<code>&lt;site&gt; Share/Photogrammetry DEMs</code>. WARNING: paths on the Google Drive are case-sensitive!</p></li>
<li><p><code>transects</code> directory with field transect shapefile</p></li>
<li><p><code>exclude</code> list of geoTIFFs to exclude, for whatever reasons. Note that files beginning with <code>bad</code> are also
excluded</p></li>
<li><p><code>sftp</code> <code>list(url = &lt;address of site&gt;, user = &lt;credentials&gt;)</code>. Credentials are either <code>username:password</code> or
<code>*filename</code> with <code>username:password</code>. Make sure
to include credential files in <code>.gitignore</code> and <code>.Rbuildignore</code> so it doesn't end up out in the world!</p></li>
</ul><p>Source data:</p><ul><li><p>geoTIFFs for each site</p></li>
<li><p><code>sites</code> file, table of site abbreviation, site name, footprint shapefile, raster standard, and transect
shapefile.</p></li>
</ul><p>Results:</p><ul><li><p>flights/geoTIFFs, clipped, resampled, and aligned. <em><strong>Make sure you've closed ArcGIS/QGIS projects that
point to these before running!</strong></em></p></li>
<li><p>models/gather_data.log</p></li>
</ul><p>All source data are expected to be in <code>EPSG:4326</code>. Non-conforming rasters will be reprojected.</p>
<p><code>sites.txt</code> must include the name of the footprint shapefile for each site, a field transect
shapefile, and a standard geoTIFF for each site. The footprint is used for clipping and must be
present. The transect contains ground truth data, and must be present if <code>field = TRUE</code>. The
standard must be present. It is used as the standard for grain and alignment; all rasters will be
resampled to match. Standards MUST be in the standard projection, <code>EPSG:4326</code>. Best to use a Mica
orthophoto, with 8 cm resolution.</p>
<p>Note that adding to an existing stack using a different standard will lead to sorrow. <strong>BEST
PRACTICE</strong>: don't change the standards in <code>standards.txt</code>; if you must change them, clear the
flights/ directory and rerun.</p>
<p>If you're reading from the Google Drive or SFTP, you'll need a cache. Best to put this on the
Unity <strong>scratch drive</strong>. Create it with <code>ws_allocate cache 30</code> in the Unity shell. You can extend
the scratch drive (up to 5 times) with <code>ws_extend cache 30</code>. When you're done with it, be polite
and release it with <code>ws_release cache</code>. You'll need to point to the cache in <code>~/pars.yml</code>, under
<code>scratchdir:</code>.</p>
<p>Note that initial runs with Google Drive in a session open the browser for authentication or wait
for input from the console, so don't run blindly when using the Google Drive</p>
<p>At the end of a run, the log file will be copied to the flights directory.</p>
<p>Remember that some SFTP servers require connection via VPN</p>
<p>Example runs:</p>
<p>Complete for all sites:</p>
<p></p><div class="sourceCode"><pre><code><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a>  <span class="st">`</span><span class="at">gather('all')</span><span class="st">`</span></span></code></pre><p></p></div>
<p>Run for one site, June only:</p>
<p></p><div class="sourceCode"><pre><code><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a>  <span class="st">`</span><span class="at">gather(site = 'oth', pattern = 'Jun')</span><span class="st">`</span></span></code></pre><p></p></div>
<p>Run for 2 sites, low tide only:</p>
<p></p><div class="sourceCode"><pre><code><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a>  <span class="st">`</span><span class="at">gather(site = c('oth', 'wes'), pattern = '_low_')</span><span class="st">`</span></span></code></pre><p></p></div>
    </div>

  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Bradley Compton.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer></div>





  </body></html>

